export default {
  description: {
    short: {
      en_US: 'Self-hosted AI platform designed to operate entirely offline',
      es_ES: 'Plataforma de IA autoalojada diseñada para funcionar completamente sin conexión',
      de_DE: 'Selbst gehostete KI-Plattform für den vollständigen Offline-Betrieb',
      pl_PL: 'Samodzielnie hostowana platforma AI zaprojektowana do pracy całkowicie offline',
      fr_FR: 'Plateforme IA auto-hébergée conçue pour fonctionner entièrement hors ligne',
    },
    long: {
      en_US: 'Open WebUI is an extensible, feature-rich, and user-friendly self-hosted AI platform designed to operate entirely offline. It supports various LLM runners like Ollama and OpenAI-compatible APIs, with built-in inference engine for RAG, making it a powerful AI deployment solution.',
      es_ES: 'Open WebUI es una plataforma de IA autoalojada extensible, rica en funciones y fácil de usar, diseñada para funcionar completamente sin conexión. Es compatible con varios ejecutores de LLM como Ollama y APIs compatibles con OpenAI, con un motor de inferencia integrado para RAG, lo que la convierte en una potente solución de despliegue de IA.',
      de_DE: 'Open WebUI ist eine erweiterbare, funktionsreiche und benutzerfreundliche selbst gehostete KI-Plattform für den vollständigen Offline-Betrieb. Sie unterstützt verschiedene LLM-Runner wie Ollama und OpenAI-kompatible APIs mit integrierter Inferenz-Engine für RAG und ist damit eine leistungsstarke KI-Bereitstellungslösung.',
      pl_PL: 'Open WebUI to rozszerzalna, bogata w funkcje i przyjazna dla użytkownika samodzielnie hostowana platforma AI zaprojektowana do pracy całkowicie offline. Obsługuje różne silniki LLM, takie jak Ollama i API kompatybilne z OpenAI, z wbudowanym silnikiem wnioskowania dla RAG, co czyni ją potężnym rozwiązaniem do wdrażania AI.',
      fr_FR: 'Open WebUI est une plateforme IA auto-hébergée extensible, riche en fonctionnalités et conviviale, conçue pour fonctionner entièrement hors ligne. Elle prend en charge divers exécuteurs LLM comme Ollama et les API compatibles OpenAI, avec un moteur d\'inférence intégré pour le RAG, ce qui en fait une solution puissante de déploiement d\'IA.',
    },
  },
}
